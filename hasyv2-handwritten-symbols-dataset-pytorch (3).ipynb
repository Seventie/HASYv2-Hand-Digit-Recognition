{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a86daa",
   "metadata": {
    "papermill": {
     "duration": 0.009475,
     "end_time": "2025-03-11T08:22:44.004307",
     "exception": false,
     "start_time": "2025-03-11T08:22:43.994832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Image Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c09e24",
   "metadata": {
    "papermill": {
     "duration": 0.008293,
     "end_time": "2025-03-11T08:22:44.021364",
     "exception": false,
     "start_time": "2025-03-11T08:22:44.013071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Necessary Libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7934793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:44.038985Z",
     "iopub.status.busy": "2025-03-11T08:22:44.038726Z",
     "iopub.status.idle": "2025-03-11T08:22:53.429644Z",
     "shell.execute_reply": "2025-03-11T08:22:53.428929Z"
    },
    "papermill": {
     "duration": 9.401548,
     "end_time": "2025-03-11T08:22:53.431239",
     "exception": false,
     "start_time": "2025-03-11T08:22:44.029691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import zipfile \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random as random \n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset , ConcatDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50704c",
   "metadata": {
    "papermill": {
     "duration": 0.008261,
     "end_time": "2025-03-11T08:22:53.448500",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.440239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the Given Data set and Understanding it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147dbd61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:53.466075Z",
     "iopub.status.busy": "2025-03-11T08:22:53.465730Z",
     "iopub.status.idle": "2025-03-11T08:22:53.852452Z",
     "shell.execute_reply": "2025-03-11T08:22:53.851786Z"
    },
    "papermill": {
     "duration": 0.397242,
     "end_time": "2025-03-11T08:22:53.854066",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.456824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading The data into A dataframe to Look at the data \n",
    "\n",
    "\n",
    "metaData = pd.read_csv(\"/kaggle/input/torch-it-up/dataset/metaData.csv\")\n",
    "\n",
    "test = pd.read_csv(\"/kaggle/input/torch-it-up/dataset/test.csv\")\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/torch-it-up/dataset/train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5ec54",
   "metadata": {
    "papermill": {
     "duration": 0.008363,
     "end_time": "2025-03-11T08:22:53.871628",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.863265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Looking Through the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee17ec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:53.889798Z",
     "iopub.status.busy": "2025-03-11T08:22:53.889510Z",
     "iopub.status.idle": "2025-03-11T08:22:53.915163Z",
     "shell.execute_reply": "2025-03-11T08:22:53.914493Z"
    },
    "papermill": {
     "duration": 0.035977,
     "end_time": "2025-03-11T08:22:53.916341",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.880364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>user_id</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12567</th>\n",
       "      <td>data/v2-99417.png</td>\n",
       "      <td>10</td>\n",
       "      <td>99417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15504</th>\n",
       "      <td>data/v2-75536.png</td>\n",
       "      <td>10</td>\n",
       "      <td>75536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>data/v2-98973.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>98973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27614</th>\n",
       "      <td>data/v2-127277.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>127277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18387</th>\n",
       "      <td>data/v2-140924.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>140924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>data/v2-132409.png</td>\n",
       "      <td>6483</td>\n",
       "      <td>132409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25941</th>\n",
       "      <td>data/v2-29020.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>29020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>data/v2-107438.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>107438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>data/v2-38103.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>38103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>data/v2-93063.png</td>\n",
       "      <td>16925</td>\n",
       "      <td>93063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_path  user_id  example_id\n",
       "12567   data/v2-99417.png       10       99417\n",
       "15504   data/v2-75536.png       10       75536\n",
       "7675    data/v2-98973.png    16925       98973\n",
       "27614  data/v2-127277.png    16925      127277\n",
       "18387  data/v2-140924.png    16925      140924\n",
       "1539   data/v2-132409.png     6483      132409\n",
       "25941   data/v2-29020.png    16925       29020\n",
       "28819  data/v2-107438.png    16925      107438\n",
       "4223    data/v2-38103.png    16925       38103\n",
       "4778    data/v2-93063.png    16925       93063"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data \n",
    "\n",
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8316d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:53.934805Z",
     "iopub.status.busy": "2025-03-11T08:22:53.934585Z",
     "iopub.status.idle": "2025-03-11T08:22:53.944412Z",
     "shell.execute_reply": "2025-03-11T08:22:53.943725Z"
    },
    "papermill": {
     "duration": 0.020347,
     "end_time": "2025-03-11T08:22:53.945638",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.925291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>symbol_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99276</th>\n",
       "      <td>141565</td>\n",
       "      <td>data/v2-141565.png</td>\n",
       "      <td>\\emptyset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10765</th>\n",
       "      <td>131693</td>\n",
       "      <td>data/v2-131693.png</td>\n",
       "      <td>\\lceil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122792</th>\n",
       "      <td>138267</td>\n",
       "      <td>data/v2-138267.png</td>\n",
       "      <td>\\infty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131374</th>\n",
       "      <td>140247</td>\n",
       "      <td>data/v2-140247.png</td>\n",
       "      <td>\\diamondsuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114574</th>\n",
       "      <td>163893</td>\n",
       "      <td>data/v2-163893.png</td>\n",
       "      <td>\\mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32812</th>\n",
       "      <td>55981</td>\n",
       "      <td>data/v2-55981.png</td>\n",
       "      <td>\\int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>60669</td>\n",
       "      <td>data/v2-60669.png</td>\n",
       "      <td>\\geq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81244</th>\n",
       "      <td>90947</td>\n",
       "      <td>data/v2-90947.png</td>\n",
       "      <td>\\oiint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48777</th>\n",
       "      <td>50836</td>\n",
       "      <td>data/v2-50836.png</td>\n",
       "      <td>\\chi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24154</th>\n",
       "      <td>62693</td>\n",
       "      <td>data/v2-62693.png</td>\n",
       "      <td>\\subseteq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        example_id          image_path   symbol_name\n",
       "99276       141565  data/v2-141565.png     \\emptyset\n",
       "10765       131693  data/v2-131693.png        \\lceil\n",
       "122792      138267  data/v2-138267.png        \\infty\n",
       "131374      140247  data/v2-140247.png  \\diamondsuit\n",
       "114574      163893  data/v2-163893.png         \\mars\n",
       "32812        55981   data/v2-55981.png          \\int\n",
       "7513         60669   data/v2-60669.png          \\geq\n",
       "81244        90947   data/v2-90947.png        \\oiint\n",
       "48777        50836   data/v2-50836.png          \\chi\n",
       "24154        62693   data/v2-62693.png     \\subseteq"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meta Data \n",
    "metaData.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa75ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:53.963991Z",
     "iopub.status.busy": "2025-03-11T08:22:53.963790Z",
     "iopub.status.idle": "2025-03-11T08:22:53.973829Z",
     "shell.execute_reply": "2025-03-11T08:22:53.973193Z"
    },
    "papermill": {
     "duration": 0.020311,
     "end_time": "2025-03-11T08:22:53.974903",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.954592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>latex</th>\n",
       "      <th>user_id</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99234</th>\n",
       "      <td>data/v2-77399.png</td>\n",
       "      <td>517</td>\n",
       "      <td>\\triangleleft</td>\n",
       "      <td>16925</td>\n",
       "      <td>77399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102705</th>\n",
       "      <td>data/v2-159075.png</td>\n",
       "      <td>1066</td>\n",
       "      <td>\\mathds{R}</td>\n",
       "      <td>16925</td>\n",
       "      <td>159075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126686</th>\n",
       "      <td>data/v2-77365.png</td>\n",
       "      <td>517</td>\n",
       "      <td>\\triangleleft</td>\n",
       "      <td>10</td>\n",
       "      <td>77365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85308</th>\n",
       "      <td>data/v2-96341.png</td>\n",
       "      <td>605</td>\n",
       "      <td>\\perp</td>\n",
       "      <td>16925</td>\n",
       "      <td>96341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59962</th>\n",
       "      <td>data/v2-138228.png</td>\n",
       "      <td>944</td>\n",
       "      <td>\\infty</td>\n",
       "      <td>16925</td>\n",
       "      <td>138228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101000</th>\n",
       "      <td>data/v2-160239.png</td>\n",
       "      <td>1074</td>\n",
       "      <td>\\mathds{Z}</td>\n",
       "      <td>16925</td>\n",
       "      <td>160239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99690</th>\n",
       "      <td>data/v2-62139.png</td>\n",
       "      <td>190</td>\n",
       "      <td>\\supset</td>\n",
       "      <td>16925</td>\n",
       "      <td>62139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123321</th>\n",
       "      <td>data/v2-14595.png</td>\n",
       "      <td>968</td>\n",
       "      <td>\\square</td>\n",
       "      <td>16925</td>\n",
       "      <td>14595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17871</th>\n",
       "      <td>data/v2-68485.png</td>\n",
       "      <td>261</td>\n",
       "      <td>\\}</td>\n",
       "      <td>6483</td>\n",
       "      <td>68485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52780</th>\n",
       "      <td>data/v2-86039.png</td>\n",
       "      <td>537</td>\n",
       "      <td>\\circ</td>\n",
       "      <td>16925</td>\n",
       "      <td>86039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image_path  label          latex  user_id  example_id\n",
       "99234    data/v2-77399.png    517  \\triangleleft    16925       77399\n",
       "102705  data/v2-159075.png   1066     \\mathds{R}    16925      159075\n",
       "126686   data/v2-77365.png    517  \\triangleleft       10       77365\n",
       "85308    data/v2-96341.png    605          \\perp    16925       96341\n",
       "59962   data/v2-138228.png    944         \\infty    16925      138228\n",
       "101000  data/v2-160239.png   1074     \\mathds{Z}    16925      160239\n",
       "99690    data/v2-62139.png    190        \\supset    16925       62139\n",
       "123321   data/v2-14595.png    968        \\square    16925       14595\n",
       "17871    data/v2-68485.png    261             \\}     6483       68485\n",
       "52780    data/v2-86039.png    537          \\circ    16925       86039"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data \n",
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98d2a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:53.993445Z",
     "iopub.status.busy": "2025-03-11T08:22:53.993240Z",
     "iopub.status.idle": "2025-03-11T08:22:53.998183Z",
     "shell.execute_reply": "2025-03-11T08:22:53.997595Z"
    },
    "papermill": {
     "duration": 0.015444,
     "end_time": "2025-03-11T08:22:53.999243",
     "exception": false,
     "start_time": "2025-03-11T08:22:53.983799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         786\n",
       "1         194\n",
       "2         951\n",
       "3         921\n",
       "4         531\n",
       "         ... \n",
       "134581    884\n",
       "134582    968\n",
       "134583    116\n",
       "134584    262\n",
       "134585    513\n",
       "Name: label, Length: 134586, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c2a01",
   "metadata": {
    "papermill": {
     "duration": 0.008646,
     "end_time": "2025-03-11T08:22:54.016822",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.008176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking for any null values in the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e3043d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.035118Z",
     "iopub.status.busy": "2025-03-11T08:22:54.034925Z",
     "iopub.status.idle": "2025-03-11T08:22:54.039124Z",
     "shell.execute_reply": "2025-03-11T08:22:54.038334Z"
    },
    "papermill": {
     "duration": 0.014697,
     "end_time": "2025-03-11T08:22:54.040377",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.025680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'label', 'latex', 'user_id', 'example_id'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca771f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.059237Z",
     "iopub.status.busy": "2025-03-11T08:22:54.059019Z",
     "iopub.status.idle": "2025-03-11T08:22:54.077257Z",
     "shell.execute_reply": "2025-03-11T08:22:54.076664Z"
    },
    "papermill": {
     "duration": 0.029042,
     "end_time": "2025-03-11T08:22:54.078372",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.049330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    0\n",
       "label         0\n",
       "latex         0\n",
       "user_id       0\n",
       "example_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e95fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.097088Z",
     "iopub.status.busy": "2025-03-11T08:22:54.096891Z",
     "iopub.status.idle": "2025-03-11T08:22:54.103354Z",
     "shell.execute_reply": "2025-03-11T08:22:54.102732Z"
    },
    "papermill": {
     "duration": 0.017187,
     "end_time": "2025-03-11T08:22:54.104621",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.087434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    0\n",
       "user_id       0\n",
       "example_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8ac8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.123348Z",
     "iopub.status.busy": "2025-03-11T08:22:54.123140Z",
     "iopub.status.idle": "2025-03-11T08:22:54.138965Z",
     "shell.execute_reply": "2025-03-11T08:22:54.138287Z"
    },
    "papermill": {
     "duration": 0.026489,
     "end_time": "2025-03-11T08:22:54.140186",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.113697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example_id     0\n",
       "image_path     0\n",
       "symbol_name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608a622",
   "metadata": {
    "papermill": {
     "duration": 0.010568,
     "end_time": "2025-03-11T08:22:54.160577",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.150009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Has many numbered labels missing so ahve to map them and demap them at submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127e139c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.180235Z",
     "iopub.status.busy": "2025-03-11T08:22:54.180019Z",
     "iopub.status.idle": "2025-03-11T08:22:54.190911Z",
     "shell.execute_reply": "2025-03-11T08:22:54.190254Z"
    },
    "papermill": {
     "duration": 0.022217,
     "end_time": "2025-03-11T08:22:54.192289",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.170072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = sorted(train[\"label\"].unique(), key=lambda x: int(x))  # Sort numerically if labels are integers\n",
    "i = 0 \n",
    "changed_labels ={}\n",
    "while (i < len(unique_labels)):\n",
    "    changed_labels [i] = unique_labels[i]\n",
    "    i+=1\n",
    "i = 0\n",
    "label_map = {v: k for k, v in changed_labels.items()} \n",
    "\n",
    "train[\"label\"] = train[\"label\"].map(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272adb7b",
   "metadata": {
    "papermill": {
     "duration": 0.009173,
     "end_time": "2025-03-11T08:22:54.211861",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.202688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking weather if lets say if each user in this has like ample no of training examples then i can train them differntly for differnet users so that when given the same userid i will train with that itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23aca7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.230890Z",
     "iopub.status.busy": "2025-03-11T08:22:54.230674Z",
     "iopub.status.idle": "2025-03-11T08:22:54.237883Z",
     "shell.execute_reply": "2025-03-11T08:22:54.237120Z"
    },
    "papermill": {
     "duration": 0.018133,
     "end_time": "2025-03-11T08:22:54.239133",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.221000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "10        3143\n",
       "14           1\n",
       "15         555\n",
       "23          38\n",
       "25           2\n",
       "          ... \n",
       "124916      46\n",
       "125926      72\n",
       "126638       2\n",
       "128674       1\n",
       "130087       2\n",
       "Length: 429, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_example_counts = train.groupby('user_id').size()\n",
    "user_example_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f52f4",
   "metadata": {
    "papermill": {
     "duration": 0.009138,
     "end_time": "2025-03-11T08:22:54.257824",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.248686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Looking at the data we cant train separately for each user so "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58837b54",
   "metadata": {
    "papermill": {
     "duration": 0.008991,
     "end_time": "2025-03-11T08:22:54.275987",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.266996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining transformation for the images to be read \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e02b8",
   "metadata": {
    "papermill": {
     "duration": 0.009002,
     "end_time": "2025-03-11T08:22:54.294225",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.285223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Isnt required as in question it is mentioned that data is already grayscaled and noramlised and ready to  train deeplearning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec89bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.313276Z",
     "iopub.status.busy": "2025-03-11T08:22:54.313066Z",
     "iopub.status.idle": "2025-03-11T08:22:54.316307Z",
     "shell.execute_reply": "2025-03-11T08:22:54.315696Z"
    },
    "papermill": {
     "duration": 0.014069,
     "end_time": "2025-03-11T08:22:54.317450",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.303381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#{ Converting the images into tensor and then normalising the data varying from 0 to 255 in terms of -1 to 1 }\n",
    "# I got to know that they were already normalised and all so i didnt scrap my existing code just commented it out \n",
    "\n",
    "# we only need to convert them into tensors \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    #transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82bf9327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.337098Z",
     "iopub.status.busy": "2025-03-11T08:22:54.336903Z",
     "iopub.status.idle": "2025-03-11T08:22:54.341112Z",
     "shell.execute_reply": "2025-03-11T08:22:54.340329Z"
    },
    "papermill": {
     "duration": 0.015234,
     "end_time": "2025-03-11T08:22:54.342365",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.327131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the max value of label \n",
    "\n",
    "train['label'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c2b79",
   "metadata": {
    "papermill": {
     "duration": 0.009059,
     "end_time": "2025-03-11T08:22:54.360806",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.351747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17335d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.380220Z",
     "iopub.status.busy": "2025-03-11T08:22:54.380001Z",
     "iopub.status.idle": "2025-03-11T08:22:54.388447Z",
     "shell.execute_reply": "2025-03-11T08:22:54.387686Z"
    },
    "papermill": {
     "duration": 0.019624,
     "end_time": "2025-03-11T08:22:54.389654",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.370030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "318    99\n",
       "29     99\n",
       "235    98\n",
       "244    97\n",
       "259    97\n",
       "       ..\n",
       "23     43\n",
       "4      43\n",
       "51     42\n",
       "356    42\n",
       "357    41\n",
       "Name: count, Length: 102, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for labels with less than 100 training examples\n",
    "\n",
    "train['label'].value_counts()[lambda x: x <100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9fc84",
   "metadata": {
    "papermill": {
     "duration": 0.009207,
     "end_time": "2025-03-11T08:22:54.408234",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.399027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Well we can do see that there are many labels with less than 100 training exmaples to keep it fair and to improve my models accuracy lets just augment images of the labels that have less than 100 training examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef319f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:54.427949Z",
     "iopub.status.busy": "2025-03-11T08:22:54.427746Z",
     "iopub.status.idle": "2025-03-11T08:22:58.834516Z",
     "shell.execute_reply": "2025-03-11T08:22:58.833602Z"
    },
    "papermill": {
     "duration": 4.418277,
     "end_time": "2025-03-11T08:22:58.836105",
     "exception": false,
     "start_time": "2025-03-11T08:22:54.417828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Applying the transformation logic for augmentation for the image dataset \n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Get data with less than 100 labels and then get them all in a list\n",
    "\n",
    "label_counts = train['label'].value_counts()\n",
    "labels_to_augment = label_counts[label_counts < 100].index\n",
    "\n",
    "# Two empty datasets (lists) to store results \n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# Looping through all the labels to augment and creating new data \n",
    "for label in labels_to_augment:\n",
    "    subset = train[train['label'] == label].iloc[:1]  # Select only one image per label\n",
    "    \n",
    "    for index, row in subset.iterrows():\n",
    "        image = Image.open(\"/kaggle/input/torch-it-up/dataset/Dataset_Image/Dataset_Image/\" + row['image_path']).convert(\"L\")\n",
    "        \n",
    "        # Generate just enough augmented images to reach 100 examples\n",
    "        needed = 200 - label_counts[label]\n",
    "\n",
    "        for _ in range(needed):\n",
    "            # Apply augmentation\n",
    "            aug_img = augment(image)\n",
    "            augmented_images.append(aug_img)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "# Convert tensors into a Tensor as a whole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cbfaae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:58.858663Z",
     "iopub.status.busy": "2025-03-11T08:22:58.858322Z",
     "iopub.status.idle": "2025-03-11T08:22:59.157189Z",
     "shell.execute_reply": "2025-03-11T08:22:59.156477Z"
    },
    "papermill": {
     "duration": 0.312087,
     "end_time": "2025-03-11T08:22:59.158763",
     "exception": false,
     "start_time": "2025-03-11T08:22:58.846676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented_images = torch.stack(augmented_images).to(device)\n",
    "\n",
    "# Converting the augmented_labels from dtype lists to tensor \n",
    "\n",
    "augmented_labels = torch.tensor(augmented_labels , dtype = torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b6bdaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:59.180512Z",
     "iopub.status.busy": "2025-03-11T08:22:59.180263Z",
     "iopub.status.idle": "2025-03-11T08:22:59.185084Z",
     "shell.execute_reply": "2025-03-11T08:22:59.184371Z"
    },
    "papermill": {
     "duration": 0.016143,
     "end_time": "2025-03-11T08:22:59.186245",
     "exception": false,
     "start_time": "2025-03-11T08:22:59.170102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Images Shape: torch.Size([13484, 1, 32, 32])\n",
      "Augmented Labels Shape: torch.Size([13484])\n",
      "Original Training Data: (134586, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Augmented Images Shape: {augmented_images.shape}\")  # Should be [N, 1, 32, 32]\n",
    "print(f\"Augmented Labels Shape: {augmented_labels.shape}\") \n",
    "print(f\"Original Training Data: {train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e05ad9",
   "metadata": {
    "papermill": {
     "duration": 0.009703,
     "end_time": "2025-03-11T08:22:59.205587",
     "exception": false,
     "start_time": "2025-03-11T08:22:59.195884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking if The Augemntation Worked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6056682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:59.225077Z",
     "iopub.status.busy": "2025-03-11T08:22:59.224873Z",
     "iopub.status.idle": "2025-03-11T08:22:59.229772Z",
     "shell.execute_reply": "2025-03-11T08:22:59.229036Z"
    },
    "papermill": {
     "duration": 0.015974,
     "end_time": "2025-03-11T08:22:59.230967",
     "exception": false,
     "start_time": "2025-03-11T08:22:59.214993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull Mate \n"
     ]
    }
   ],
   "source": [
    "# Checking My new data \n",
    "\n",
    "# Convert tensors to Python sets for easy comparison\n",
    "unique_augmented_labels = set(augmented_labels.tolist())\n",
    "labels_to_augment_set = set(labels_to_augment)\n",
    "\n",
    "# Check which labels are missing\n",
    "missing_augmented_labels = labels_to_augment_set - unique_augmented_labels\n",
    "\n",
    "# Print results\n",
    "if len(missing_augmented_labels) > 0:\n",
    "    print(\"Some Lables are surely Missing They are \", missing_augmented_labels)\n",
    "else:\n",
    "    print(\"Successfull Mate \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c777ef",
   "metadata": {
    "papermill": {
     "duration": 0.009591,
     "end_time": "2025-03-11T08:22:59.250193",
     "exception": false,
     "start_time": "2025-03-11T08:22:59.240602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Concatenating augemnted data and existing data and oading them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ae3f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:22:59.269998Z",
     "iopub.status.busy": "2025-03-11T08:22:59.269801Z",
     "iopub.status.idle": "2025-03-11T08:23:01.988691Z",
     "shell.execute_reply": "2025-03-11T08:23:01.987997Z"
    },
    "papermill": {
     "duration": 2.730538,
     "end_time": "2025-03-11T08:23:01.990229",
     "exception": false,
     "start_time": "2025-03-11T08:22:59.259691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-28401da3ee96>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  training_images , training_labels = torch.load('/kaggle/input/data-train/processed_training_data.pt')\n"
     ]
    }
   ],
   "source": [
    "# # Getting my training data set ready \n",
    "\n",
    "# training_images = [transform(Image.open(\"/kaggle/input/torch-it-up/dataset/Dataset_Image/Dataset_Image/\" + path).convert(\"L\")) for path in train[\"image_path\"]]\n",
    "\n",
    "# # Convert labels to tensor \n",
    "# # I defined it as int16 cause max value was only 1400\n",
    "\n",
    "# training_labels = torch.tensor(train[\"label\"].values, dtype=torch.long)  \n",
    "\n",
    "\n",
    "# As it takes very long ihave downloaded from my previous excutions \n",
    "\n",
    "training_images , training_labels = torch.load('/kaggle/input/data-train/processed_training_data.pt')\n",
    "\n",
    "training_images = training_images.to(device)\n",
    "training_labels = training_labels.to(device)\n",
    "\n",
    "# creatinga tensordataset out of tensors i have \n",
    "training_set = TensorDataset(training_images, training_labels)\n",
    "\n",
    "augmented_set = TensorDataset(augmented_images, augmented_labels)\n",
    "\n",
    "# Merge both datasets using ConcatDataset\n",
    "train_dataset = ConcatDataset([training_set, augmented_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cad7758b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:02.011086Z",
     "iopub.status.busy": "2025-03-11T08:23:02.010854Z",
     "iopub.status.idle": "2025-03-11T08:23:02.014032Z",
     "shell.execute_reply": "2025-03-11T08:23:02.013441Z"
    },
    "papermill": {
     "duration": 0.014578,
     "end_time": "2025-03-11T08:23:02.015176",
     "exception": false,
     "start_time": "2025-03-11T08:23:02.000598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data to the loader \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9614b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:02.071002Z",
     "iopub.status.busy": "2025-03-11T08:23:02.070747Z",
     "iopub.status.idle": "2025-03-11T08:23:03.560710Z",
     "shell.execute_reply": "2025-03-11T08:23:03.559610Z"
    },
    "papermill": {
     "duration": 1.537236,
     "end_time": "2025-03-11T08:23:03.562248",
     "exception": false,
     "start_time": "2025-03-11T08:23:02.025012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    if images.shape[1] !=1 :\n",
    "        print(\"stop\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653211a0",
   "metadata": {
    "papermill": {
     "duration": 0.009568,
     "end_time": "2025-03-11T08:23:03.582010",
     "exception": false,
     "start_time": "2025-03-11T08:23:03.572442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Test_data into DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ad31cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:03.602172Z",
     "iopub.status.busy": "2025-03-11T08:23:03.601936Z",
     "iopub.status.idle": "2025-03-11T08:23:03.605276Z",
     "shell.execute_reply": "2025-03-11T08:23:03.604648Z"
    },
    "papermill": {
     "duration": 0.014814,
     "end_time": "2025-03-11T08:23:03.606433",
     "exception": false,
     "start_time": "2025-03-11T08:23:03.591619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting my testing data set ready\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# testing_images = [test_transform(Image.open(\"/kaggle/input/torch-it-up/dataset/Dataset_Image/Dataset_Image/\" + path)) for path in test[\"image_path\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06484052",
   "metadata": {
    "papermill": {
     "duration": 0.009472,
     "end_time": "2025-03-11T08:23:03.625739",
     "exception": false,
     "start_time": "2025-03-11T08:23:03.616267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## I have Just Noticed That even if max is 1400 \"The label Numebr \" we only do have 369 labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0d37263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:03.646065Z",
     "iopub.status.busy": "2025-03-11T08:23:03.645866Z",
     "iopub.status.idle": "2025-03-11T08:23:03.651007Z",
     "shell.execute_reply": "2025-03-11T08:23:03.650330Z"
    },
    "papermill": {
     "duration": 0.016904,
     "end_time": "2025-03-11T08:23:03.652194",
     "exception": false,
     "start_time": "2025-03-11T08:23:03.635290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: 369\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in dataset:\", train[\"label\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6147be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:03.672854Z",
     "iopub.status.busy": "2025-03-11T08:23:03.672658Z",
     "iopub.status.idle": "2025-03-11T08:23:04.358428Z",
     "shell.execute_reply": "2025-03-11T08:23:04.357624Z"
    },
    "papermill": {
     "duration": 0.697885,
     "end_time": "2025-03-11T08:23:04.360149",
     "exception": false,
     "start_time": "2025-03-11T08:23:03.662264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-890550f98ca8>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  testing_images = torch.load('/kaggle/input/testing-data-tensor/processed_training_data (1).pt')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testing_images = torch.load('/kaggle/input/testing-data-tensor/processed_training_data (1).pt')\n",
    "\n",
    "# Convert labels to tensor \n",
    "\n",
    "example_ids = torch.tensor(test[\"example_id\"].values, dtype=torch.long)  \n",
    "\n",
    "# creatinga tensordataset out of tensors i have \n",
    "testing_dataset = TensorDataset(testing_images, example_ids)\n",
    "\n",
    "#Loading all data into train_loader \n",
    "\n",
    "test_loader = DataLoader(testing_dataset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2f9da",
   "metadata": {
    "papermill": {
     "duration": 0.011684,
     "end_time": "2025-03-11T08:23:04.384159",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.372475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optional (Part If Augmentation Not needed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71af7292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.407711Z",
     "iopub.status.busy": "2025-03-11T08:23:04.407429Z",
     "iopub.status.idle": "2025-03-11T08:23:04.410564Z",
     "shell.execute_reply": "2025-03-11T08:23:04.409827Z"
    },
    "papermill": {
     "duration": 0.016497,
     "end_time": "2025-03-11T08:23:04.411959",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.395462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting ,y training data set ready \n",
    "\n",
    "# training_images = [transform(Image.open(\"/kaggle/input/torch-it-up/dataset/Dataset_Image/Dataset_Image/\" + path)) for path in train[\"image_path\"]]\n",
    "\n",
    "# # Convert labels to tensor \n",
    "# # I defined it as int16 cause max value was only 1400\n",
    "\n",
    "# training_labels = torch.tensor(train[\"label\"].values, dtype=torch.int16)  \n",
    "\n",
    "# # creatinga tensordataset out of tensors i have \n",
    "# training_set = TensorDataset(torch.stack(training_images), training_labels)\n",
    "\n",
    "# trainloader = DataLoader(training_set, batch_size=256, shuffle=True)\n",
    "\n",
    "# # Checking for data in a batch \n",
    "# for images, labels in trainloader:\n",
    "#     print(images.shape)  \n",
    "#     print(labels.shape)  \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de1899",
   "metadata": {
    "papermill": {
     "duration": 0.010972,
     "end_time": "2025-03-11T08:23:04.434205",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.423233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualising Some Samples from the training_data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e1b4a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.457385Z",
     "iopub.status.busy": "2025-03-11T08:23:04.457144Z",
     "iopub.status.idle": "2025-03-11T08:23:04.756075Z",
     "shell.execute_reply": "2025-03-11T08:23:04.755299Z"
    },
    "papermill": {
     "duration": 0.31196,
     "end_time": "2025-03-11T08:23:04.757288",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.445328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing some samples from the dataset\n",
    "\n",
    "def show_images(loader):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(images[i][0].cpu().numpy(), cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81429180",
   "metadata": {
    "papermill": {
     "duration": 0.010042,
     "end_time": "2025-03-11T08:23:04.778310",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.768268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Our Neural Network To work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20099efb",
   "metadata": {
    "papermill": {
     "duration": 0.009798,
     "end_time": "2025-03-11T08:23:04.798515",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.788717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How The Neural Network Works :-\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a35729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.819378Z",
     "iopub.status.busy": "2025-03-11T08:23:04.819129Z",
     "iopub.status.idle": "2025-03-11T08:23:04.826518Z",
     "shell.execute_reply": "2025-03-11T08:23:04.825920Z"
    },
    "papermill": {
     "duration": 0.0192,
     "end_time": "2025-03-11T08:23:04.827702",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.808502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # class ConvNet(nn.Module):\n",
    "#     # def __init__(self):\n",
    "#     #     super(ConvNet, self).__init__()\n",
    "#     #     self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "#     #     self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#     #     self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#     #     self.pool = nn.MaxPool2d(2, 2)\n",
    "#     #     self.fc1 = nn.Linear(4 * 4 * 128, 128)\n",
    "#     #     self.fc2 = nn.Linear(128, 369)\n",
    "\n",
    "    \n",
    "#     # def forward(self, x):\n",
    "#     #     x = self.pool(F.relu(self.conv1(x)))\n",
    "#     #     x = self.pool(F.relu(self.conv2(x)))\n",
    "#     #     x = self.pool(F.relu(self.conv3(x)))\n",
    "#     #     x = x.view(-1, 4 * 4 * 128)\n",
    "#     #     x = F.relu(self.fc1(x))\n",
    "#     #     x = self.fc2(x)\n",
    "#     #     return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "        \n",
    "#         # Convolutional Layers\n",
    "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(32)  \n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(64)  \n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(128)  \n",
    "        \n",
    "#         # Pooling\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "#         self.fc1 = nn.Linear(4 * 4 * 128, 256)  \n",
    "#         self.dropout1 = nn.Dropout(0.4)  \n",
    "#         self.fc2 = nn.Linear(256, 128)  \n",
    "#         self.dropout2 = nn.Dropout(0.3)\n",
    "#         self.fc3 = nn.Linear(128, 369)  \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Conv Block 1\n",
    "#         x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "#         # Conv Block 2\n",
    "#         x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "#         # Conv Block 3\n",
    "#         x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "#         # Adaptive Pooling\n",
    "#         x = self.adaptive_pool(x)\n",
    "        \n",
    "#         # Flatten\n",
    "#         x = x.view(-1, 4 * 4 * 128)\n",
    "        \n",
    "#         # Fully Connected Layers\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout1(x)  # Dropout after FC1\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.dropout2(x)  # Dropout after FC2\n",
    "#         x = self.fc3(x)  # No activation (CrossEntropyLoss expects raw logits)\n",
    "        \n",
    "#         return x  # Removed log_softmax since loss function handles it\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)  \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)  \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)  \n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.fc1 = nn.Linear(4 * 4 * 256, 512)  \n",
    "        self.dropout1 = nn.Dropout(0.5)  \n",
    "        self.fc2 = nn.Linear(512, 256)  \n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(256, 128)  \n",
    "        self.fc4 = nn.Linear(128, 369)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(-1, 4 * 4 * 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf285d",
   "metadata": {
    "papermill": {
     "duration": 0.009803,
     "end_time": "2025-03-11T08:23:04.847445",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.837642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initalsing My neural Network Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dd692cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.868736Z",
     "iopub.status.busy": "2025-03-11T08:23:04.868477Z",
     "iopub.status.idle": "2025-03-11T08:23:04.897073Z",
     "shell.execute_reply": "2025-03-11T08:23:04.896490Z"
    },
    "papermill": {
     "duration": 0.040439,
     "end_time": "2025-03-11T08:23:04.898267",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.857828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902890e9",
   "metadata": {
    "papermill": {
     "duration": 0.009929,
     "end_time": "2025-03-11T08:23:04.918166",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.908237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optimiser and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be6d3d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.939189Z",
     "iopub.status.busy": "2025-03-11T08:23:04.938926Z",
     "iopub.status.idle": "2025-03-11T08:23:04.949270Z",
     "shell.execute_reply": "2025-03-11T08:23:04.948726Z"
    },
    "papermill": {
     "duration": 0.022157,
     "end_time": "2025-03-11T08:23:04.950395",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.928238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Optimizer and Loss Function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)  # Reduce LR every 10 epochs\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e8786",
   "metadata": {
    "papermill": {
     "duration": 0.009877,
     "end_time": "2025-03-11T08:23:04.970275",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.960398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions for Training The Model and evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02903a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:04.991228Z",
     "iopub.status.busy": "2025-03-11T08:23:04.991027Z",
     "iopub.status.idle": "2025-03-11T08:23:04.996246Z",
     "shell.execute_reply": "2025-03-11T08:23:04.995703Z"
    },
    "papermill": {
     "duration": 0.016897,
     "end_time": "2025-03-11T08:23:04.997377",
     "exception": false,
     "start_time": "2025-03-11T08:23:04.980480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method To Initialise the Training of the Model\n",
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = (correct_predictions / len(loader.dataset)) * 100\n",
    "    return epoch_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c934f",
   "metadata": {
    "papermill": {
     "duration": 0.009914,
     "end_time": "2025-03-11T08:23:05.017344",
     "exception": false,
     "start_time": "2025-03-11T08:23:05.007430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and validating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bb62f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:05.038084Z",
     "iopub.status.busy": "2025-03-11T08:23:05.037861Z",
     "iopub.status.idle": "2025-03-11T08:23:05.041072Z",
     "shell.execute_reply": "2025-03-11T08:23:05.040310Z"
    },
    "papermill": {
     "duration": 0.014851,
     "end_time": "2025-03-11T08:23:05.042197",
     "exception": false,
     "start_time": "2025-03-11T08:23:05.027346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and Validation Loop\n",
    "num_epochs = 10  # Number of rounds to train the data\n",
    "train_losses, train_accuracies = [], []  # Cache all the training values in a list\n",
    "test_losses, test_accuracies = [], []   # Cache all the testing values in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7754f791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:23:05.062895Z",
     "iopub.status.busy": "2025-03-11T08:23:05.062675Z",
     "iopub.status.idle": "2025-03-11T08:25:59.177043Z",
     "shell.execute_reply": "2025-03-11T08:25:59.176101Z"
    },
    "papermill": {
     "duration": 174.136918,
     "end_time": "2025-03-11T08:25:59.189099",
     "exception": false,
     "start_time": "2025-03-11T08:23:05.052181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.2837, Train Acc: 46.27%\n",
      "Epoch 2: Train Loss: 1.1346, Train Acc: 68.20%\n",
      "Epoch 3: Train Loss: 0.8666, Train Acc: 74.85%\n",
      "Epoch 4: Train Loss: 0.7516, Train Acc: 77.62%\n",
      "Epoch 5: Train Loss: 0.6801, Train Acc: 79.39%\n",
      "Epoch 6: Train Loss: 0.6293, Train Acc: 80.65%\n",
      "Epoch 7: Train Loss: 0.5879, Train Acc: 81.53%\n",
      "Epoch 8: Train Loss: 0.5599, Train Acc: 82.24%\n",
      "Epoch 9: Train Loss: 0.5354, Train Acc: 82.85%\n",
      "Epoch 10: Train Loss: 0.5142, Train Acc: 83.29%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd336f43",
   "metadata": {
    "papermill": {
     "duration": 0.01033,
     "end_time": "2025-03-11T08:25:59.210401",
     "exception": false,
     "start_time": "2025-03-11T08:25:59.200071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Just cheking My mapping Cuase i did the Mapping Worng Initially "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e045532",
   "metadata": {
    "papermill": {
     "duration": 0.010247,
     "end_time": "2025-03-11T08:25:59.231053",
     "exception": false,
     "start_time": "2025-03-11T08:25:59.220806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Again "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f413d",
   "metadata": {
    "papermill": {
     "duration": 0.010271,
     "end_time": "2025-03-11T08:25:59.251666",
     "exception": false,
     "start_time": "2025-03-11T08:25:59.241395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Output File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6517c5a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:25:59.273824Z",
     "iopub.status.busy": "2025-03-11T08:25:59.273538Z",
     "iopub.status.idle": "2025-03-11T08:25:59.276668Z",
     "shell.execute_reply": "2025-03-11T08:25:59.275846Z"
    },
    "papermill": {
     "duration": 0.015848,
     "end_time": "2025-03-11T08:25:59.277858",
     "exception": false,
     "start_time": "2025-03-11T08:25:59.262010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.remove(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc749306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:25:59.299553Z",
     "iopub.status.busy": "2025-03-11T08:25:59.299328Z",
     "iopub.status.idle": "2025-03-11T08:28:54.293704Z",
     "shell.execute_reply": "2025-03-11T08:28:54.292817Z"
    },
    "papermill": {
     "duration": 175.017532,
     "end_time": "2025-03-11T08:28:54.306079",
     "exception": false,
     "start_time": "2025-03-11T08:25:59.288547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.4128, Train Acc: 86.04%\n",
      "Epoch 2: Train Loss: 0.3872, Train Acc: 86.68%\n",
      "Epoch 3: Train Loss: 0.3732, Train Acc: 87.02%\n",
      "Epoch 4: Train Loss: 0.3635, Train Acc: 87.14%\n",
      "Epoch 5: Train Loss: 0.3530, Train Acc: 87.46%\n",
      "Epoch 6: Train Loss: 0.3447, Train Acc: 87.68%\n",
      "Epoch 7: Train Loss: 0.3354, Train Acc: 87.87%\n",
      "Epoch 8: Train Loss: 0.3309, Train Acc: 88.07%\n",
      "Epoch 9: Train Loss: 0.3223, Train Acc: 88.16%\n",
      "Epoch 10: Train Loss: 0.3143, Train Acc: 88.46%\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation Loop\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.7)\n",
    "\n",
    "num_epochs = 10  # Number of rounds to train the data\n",
    "train_losses, train_accuracies = [], []  # Cache all the training values in a list\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "926d71a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:28:54.328630Z",
     "iopub.status.busy": "2025-03-11T08:28:54.328351Z",
     "iopub.status.idle": "2025-03-11T08:28:54.332220Z",
     "shell.execute_reply": "2025-03-11T08:28:54.331621Z"
    },
    "papermill": {
     "duration": 0.016319,
     "end_time": "2025-03-11T08:28:54.333280",
     "exception": false,
     "start_time": "2025-03-11T08:28:54.316961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a6f6b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:28:54.356099Z",
     "iopub.status.busy": "2025-03-11T08:28:54.355870Z",
     "iopub.status.idle": "2025-03-11T08:31:48.830643Z",
     "shell.execute_reply": "2025-03-11T08:31:48.829753Z"
    },
    "papermill": {
     "duration": 174.499637,
     "end_time": "2025-03-11T08:31:48.843769",
     "exception": false,
     "start_time": "2025-03-11T08:28:54.344132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.2847, Train Acc: 89.45%\n",
      "Epoch 2: Train Loss: 0.2760, Train Acc: 89.61%\n",
      "Epoch 3: Train Loss: 0.2727, Train Acc: 89.70%\n",
      "Epoch 4: Train Loss: 0.2681, Train Acc: 89.84%\n",
      "Epoch 5: Train Loss: 0.2669, Train Acc: 89.94%\n",
      "Epoch 6: Train Loss: 0.2628, Train Acc: 90.06%\n",
      "Epoch 7: Train Loss: 0.2600, Train Acc: 90.16%\n",
      "Epoch 8: Train Loss: 0.2568, Train Acc: 90.34%\n",
      "Epoch 9: Train Loss: 0.2553, Train Acc: 90.26%\n",
      "Epoch 10: Train Loss: 0.2508, Train Acc: 90.45%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Number of rounds to train the data\n",
    "train_losses, train_accuracies = [], []  # Cache all the training values in a list\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c48499e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:31:48.871625Z",
     "iopub.status.busy": "2025-03-11T08:31:48.871337Z",
     "iopub.status.idle": "2025-03-11T08:31:48.875428Z",
     "shell.execute_reply": "2025-03-11T08:31:48.874611Z"
    },
    "papermill": {
     "duration": 0.019219,
     "end_time": "2025-03-11T08:31:48.876618",
     "exception": false,
     "start_time": "2025-03-11T08:31:48.857399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "992084ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:31:48.902892Z",
     "iopub.status.busy": "2025-03-11T08:31:48.902634Z",
     "iopub.status.idle": "2025-03-11T08:31:50.535151Z",
     "shell.execute_reply": "2025-03-11T08:31:50.534210Z"
    },
    "papermill": {
     "duration": 1.648093,
     "end_time": "2025-03-11T08:31:50.536597",
     "exception": false,
     "start_time": "2025-03-11T08:31:48.888504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Mate \n"
     ]
    }
   ],
   "source": [
    "## Get The Results and save into csv for further submisiion\n",
    "\n",
    "model.eval()\n",
    "predict = []\n",
    "example_ids = []\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for images, ex_ids in test_loader:  \n",
    "        images = images.to(device)  \n",
    "        outputs = model(images)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        predict.extend(predicted_labels)\n",
    "        example_ids.extend(ex_ids.numpy())  \n",
    "\n",
    "# Convert predicted labels back to original IDs\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}  \n",
    "original_predictions = [reverse_label_map[pred] for pred in predict]  \n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"example_id\": example_ids,\n",
    "    \"predicted_label\": original_predictions  \n",
    "})\n",
    "\n",
    "# Save the output labels to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)  \n",
    "\n",
    "print(\"Completed Mate \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95898c9",
   "metadata": {
    "papermill": {
     "duration": 0.011229,
     "end_time": "2025-03-11T08:31:50.559817",
     "exception": false,
     "start_time": "2025-03-11T08:31:50.548588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11353777,
     "sourceId": 95320,
     "sourceType": "competition"
    },
    {
     "datasetId": 6839554,
     "sourceId": 10988888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6839571,
     "sourceId": 10988913,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 550.779378,
   "end_time": "2025-03-11T08:31:52.192625",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T08:22:41.413247",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
